{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "CHECK_OPENCV2 = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "if CHECK_OPENCV2 in sys.path:\n",
    "    sys.path.remove(CHECK_OPENCV2)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import network_placeholders, config_parser\n",
    "from models.detector.detector import Detector\n",
    "#from models.loss import detection_loss as loss_fn\n",
    "from data import dataloader\n",
    "from cfg import config_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.box_utils import box_iou_tf\n",
    "from utils.utils import INT, FLOAT, BOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_shapes(detections):\n",
    "    return [\n",
    "       (detection.shape[1], detection.shape[2]) for detection in detections\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_grid_offsets(grid_x_num, grid_y_num, batch_size, anchor_size):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    intermediate_center_x_offset = tf.broadcast_to(\n",
    "        tf.range(grid_x_num, dtype=tf.float32),\n",
    "        [grid_y_num, grid_x_num]\n",
    "    )\n",
    "    center_x_offsets = tf.broadcast_to(\n",
    "        intermediate_center_x_offset,\n",
    "        [batch_size, anchor_size, grid_y_num, grid_x_num]\n",
    "    )\n",
    "    intermediate_center_y_offset = tf.broadcast_to(\n",
    "        tf.range(grid_y_num, dtype=tf.float32),\n",
    "        [grid_x_num, grid_y_num]\n",
    "    )\n",
    "    intermediate_center_y_offset = tf.transpose(intermediate_center_y_offset)\n",
    "    center_y_offsets = tf.broadcast_to(\n",
    "        intermediate_center_y_offset,\n",
    "        [batch_size, anchor_size, grid_y_num, grid_x_num]\n",
    "    )\n",
    "    return center_x_offsets, center_y_offsets\n",
    "\n",
    "\n",
    "def get_anchor_wh_offsets(w_index,\n",
    "                          h_index,\n",
    "                          anchors,\n",
    "                          grid_x,\n",
    "                          grid_y,\n",
    "                          batch_size):\n",
    "    anchor_size = anchors.shape[0]\n",
    "    w_offsets = tf.broadcast_to(\n",
    "        tf.expand_dims(\n",
    "            tf.broadcast_to(\n",
    "                tf.expand_dims(\n",
    "                    tf.broadcast_to(\n",
    "                        tf.expand_dims(anchors[:, w_index], axis=-1),\n",
    "                        [anchor_size, grid_y]),\n",
    "                    axis=-1),\n",
    "                [anchor_size, grid_y, grid_x]),\n",
    "            axis=0),\n",
    "        [batch_size, anchor_size, grid_y, grid_x]\n",
    "    )\n",
    "\n",
    "    h_offsets = tf.broadcast_to(\n",
    "        tf.expand_dims(\n",
    "            tf.broadcast_to(\n",
    "                tf.expand_dims(\n",
    "                    tf.broadcast_to(\n",
    "                        tf.expand_dims(anchors[:, h_index], axis=-1),\n",
    "                        [anchor_size, grid_y]),\n",
    "                    axis=-1),\n",
    "                [anchor_size, grid_y, grid_x]),\n",
    "            axis=0),\n",
    "        [batch_size, anchor_size, grid_y, grid_x]\n",
    "    )\n",
    "    return w_offsets, h_offsets\n",
    "\n",
    "\n",
    "def convert_gt_for_loss(ground_truth,\n",
    "                        prior_x,\n",
    "                        prior_y,\n",
    "                        matched_anchors,\n",
    "                        image_width,\n",
    "                        image_height,\n",
    "                        grid_x,\n",
    "                        grid_y):\n",
    "    w_index = 0\n",
    "    h_index = 1\n",
    "    x_index, y_index, w_ind, h_ind = 0, 1, 2, 3\n",
    "\n",
    "    ground_truth_x = (ground_truth[:, x_index] * grid_x) - tf.cast(prior_x,\n",
    "                                                                   dtype=FLOAT)\n",
    "    ground_truth_y = (ground_truth[:, y_index] * grid_y) - tf.cast(prior_y,\n",
    "                                                                   dtype=FLOAT)\n",
    "    ground_truth_w = tf.math.log(ground_truth[:, w_ind] * (image_width/matched_anchors[:, w_index]))\n",
    "    ground_truth_h = tf.math.log(ground_truth[:, h_ind] * (image_height/matched_anchors[:, h_index]))\n",
    "\n",
    "    return tf.stack(\n",
    "        [ground_truth_x,\n",
    "         ground_truth_y,\n",
    "         ground_truth_w,\n",
    "         ground_truth_h],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "\n",
    "def get_localization_loss(loss_map, true, pred):\n",
    "    return loss_map['mse'](true, pred)\n",
    "\n",
    "\n",
    "def get_noobj_loss(loss_map, true, pred):\n",
    "    return loss_map['bce'](true, pred)\n",
    "\n",
    "\n",
    "def get_obj_loss(loss_map, true, pred):\n",
    "    return loss_map['bce'](true, pred)\n",
    "\n",
    "\n",
    "def get_class_loss(loss_map, true, pred):\n",
    "    return loss_map['bce'](true, pred)\n",
    "\n",
    "\n",
    "def get_loss_per_grid_detection(detection_output,\n",
    "                                loss_map,\n",
    "                                ground_truth,\n",
    "                                anchors,\n",
    "                                grid_shape,\n",
    "                                image_wh,\n",
    "                                batch_size,\n",
    "                                num_classes):\n",
    "    losses = {\n",
    "        'regression_loss': 0.0,\n",
    "        'objectness_loss': 0.0,\n",
    "        'noobjectness_loss': 0.0,\n",
    "        'classification_loss': 0.0,\n",
    "        'total_loss': 0.0,\n",
    "        'valid': True\n",
    "    }\n",
    "    valid_matches = True\n",
    "    num_anchors = len(anchors)\n",
    "    grid_x, grid_y = grid_shape\n",
    "    image_width, image_height = image_wh\n",
    "    width_downsampling_factor = image_width/grid_x\n",
    "    height_downsampling_factor = image_height/grid_y\n",
    "    num_channels = detection_output.shape[-1]\n",
    "    prediction_channels = tf.cast(num_channels/num_anchors, dtype=INT)\n",
    "    num_gt = ground_truth.shape[0]\n",
    "    \n",
    "    print(\"anchors: {}\".format(anchors))\n",
    "    print(\"grid_x {}, grid_y {}\".format(grid_x, grid_y))\n",
    "    print(\"\")\n",
    "\n",
    "    # ground truth tensors\n",
    "    ground_truth_bbox = ground_truth[:, 1:-1]\n",
    "    ground_truth_wh_bbox = tf.concat(\n",
    "        [\n",
    "            tf.zeros_like(ground_truth_bbox[:, -2:]),\n",
    "            ground_truth_bbox[:, -2:]\n",
    "        ],\n",
    "        axis=-1\n",
    "    )\n",
    "    ground_truth_classes = tf.cast(ground_truth[:, -1], dtype=INT)\n",
    "    ground_truth_classes_onehot = tf.one_hot(ground_truth_classes, depth=num_classes)\n",
    "    ground_truth_batch_indices = tf.cast(ground_truth[:, 0], dtype=INT)\n",
    "    ground_truth_x = ground_truth_bbox[:, 0]\n",
    "    ground_truth_y = ground_truth_bbox[:, 1]\n",
    "    ground_truth_x_scaled = ground_truth_x * grid_x\n",
    "    ground_truth_y_scaled = ground_truth_y * grid_y\n",
    "\n",
    "    # anchors tensor\n",
    "    anchors_tensor = tf.constant(anchors, dtype=FLOAT)\n",
    "    anchors_normalized = tf.math.divide(anchors_tensor,\n",
    "                                        tf.broadcast_to(\n",
    "                                            tf.expand_dims(\n",
    "                                                tf.constant([float(image_width), float(image_height)], dtype=FLOAT),\n",
    "                                                axis=0),\n",
    "                                            [anchors_tensor.shape[0], anchors_tensor.shape[1]]\n",
    "                                        )\n",
    "                                       )\n",
    "    anchors_normalized_bbox = tf.concat(\n",
    "        [tf.zeros_like(anchors_normalized),\n",
    "         anchors_normalized],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    # x & y - offsets\n",
    "    center_x, center_y = get_grid_offsets(grid_x,\n",
    "                                          grid_y,\n",
    "                                          batch_size,\n",
    "                                          num_anchors)\n",
    "\n",
    "    output_reshaped = tf.reshape(detection_output,\n",
    "                                 [batch_size,\n",
    "                                  num_anchors,\n",
    "                                  grid_y,\n",
    "                                  grid_x,\n",
    "                                  prediction_channels])\n",
    "\n",
    "    # separate into bounding boxes, objectness score and classes\n",
    "    output_bboxes = output_reshaped[:, :, :, :, :4] # first four indices are bounding box predictions\n",
    "    output_objectness = output_reshaped[:, :, :, :, 4] # fifth index is objectness score\n",
    "    output_classes = output_reshaped[:, :, :, :, 5:] # 6th onwards are class predictons\n",
    "    predicted_objectness = tf.math.sigmoid(output_objectness)\n",
    "    predicted_classes = tf.math.sigmoid(output_classes)\n",
    "\n",
    "    # get predictions\n",
    "    # first get anchor offsets to be added\n",
    "    w_index = 0\n",
    "    h_index = 1\n",
    "    w_offsets, h_offsets = get_anchor_wh_offsets(w_index,\n",
    "                                                 h_index,\n",
    "                                                 anchors_tensor,\n",
    "                                                 grid_x,\n",
    "                                                 grid_y,\n",
    "                                                 batch_size)\n",
    "\n",
    "    predicted_x = (tf.math.sigmoid(output_bboxes[..., 0]) + center_x) / grid_x\n",
    "    predicted_y = (tf.math.sigmoid(output_bboxes[..., 1]) + center_y) / grid_y\n",
    "    predicted_w = (tf.exp(output_bboxes[..., 2]) * w_offsets)/image_width\n",
    "    predicted_h = (tf.exp(output_bboxes[..., 3]) * h_offsets)/image_height\n",
    "\n",
    "    # get iou between groundtruth and prior box anchors\n",
    "    iou_anchor_gt = box_iou_tf(anchors_normalized_bbox, ground_truth_wh_bbox)\n",
    "    print(\"iou(anchors, gt)\")\n",
    "    print(iou_anchor_gt)\n",
    "    print(\"\")\n",
    "    \n",
    "    if tf.reduce_any(iou_anchor_gt > 0.5):\n",
    "        valid_matches = True\n",
    "    else:\n",
    "        valid_matches = False\n",
    "\n",
    "    max_iou_anchor_indices = tf.cast(tf.argmax(iou_anchor_gt, axis=-1), dtype=INT)\n",
    "    max_iou_anchor_indices_extra_dim = tf.stack(\n",
    "        [tf.zeros_like(max_iou_anchor_indices, dtype=INT),\n",
    "         max_iou_anchor_indices],\n",
    "        axis=-1\n",
    "    )\n",
    "    print(\"max iou anchor indices per gt\")\n",
    "    print(max_iou_anchor_indices)\n",
    "    print(\"\")\n",
    "\n",
    "    # ground truth prior box indiices\n",
    "    priors_x = tf.cast(ground_truth_x_scaled, dtype=INT)\n",
    "    priors_y = tf.cast(ground_truth_y_scaled, dtype=INT)\n",
    "    prior_indices = tf.stack([ground_truth_batch_indices,\n",
    "                              max_iou_anchor_indices,\n",
    "                              priors_y,\n",
    "                              priors_x], axis=-1)\n",
    "    print(\"prior indices\")\n",
    "    print(prior_indices)\n",
    "    print(\"\")\n",
    "    anchors_broadcasted = tf.broadcast_to(anchors_tensor,\n",
    "                                          (num_gt, ) + anchors_tensor.shape)\n",
    "    matched_anchors = tf.gather_nd(anchors_broadcasted, max_iou_anchor_indices_extra_dim)\n",
    "\n",
    "    # get the converted gt and the matched priors from predictions\n",
    "    priors_from_preds = tf.gather_nd(output_bboxes, prior_indices)\n",
    "    print(\"priors from preds\")\n",
    "    print(priors_from_preds)\n",
    "    print(\"\")\n",
    "\n",
    "    converted_gt = convert_gt_for_loss(ground_truth_bbox,\n",
    "                                       priors_x, priors_y,\n",
    "                                       matched_anchors,\n",
    "                                       image_width,\n",
    "                                       image_height,\n",
    "                                       grid_x,\n",
    "                                       grid_y)\n",
    "    print(\"convert gt\")\n",
    "    print(converted_gt)\n",
    "    print(\"\")\n",
    "\n",
    "    # at this step, you can get localization loss from priors_from_preds\n",
    "    # and converted_gt\n",
    "    if valid_matches:\n",
    "        localization_loss = get_localization_loss(loss_map, converted_gt, priors_from_preds)\n",
    "    else:\n",
    "        localization_loss = tf.constant(0.0)\n",
    "    print(\"localization loss: {}\".format(localization_loss))\n",
    "\n",
    "    # get no_obj loss, obj loss and classification loss.\n",
    "    # noobj loss\n",
    "    predicted_bboxes = tf.stack([predicted_x,\n",
    "                                 predicted_y,\n",
    "                                 predicted_w,\n",
    "                                 predicted_h],\n",
    "                                axis=-1)\n",
    "    predicted_bboxes_flattened = tf.reshape(predicted_bboxes, [-1, 4]) # flatten all bounding boxes to a Tensor of rank 2\n",
    "    iou_predictions_gt = box_iou_tf(ground_truth_bbox,\n",
    "                                    predicted_bboxes_flattened)\n",
    "    \n",
    "    # get noobj_masks\n",
    "    noobj_mask_candidates = tf.where(\n",
    "        tf.math.reduce_max(iou_predictions_gt,\n",
    "                           axis=-1) > 0.5, # ignore_threshold\n",
    "        False,\n",
    "        True\n",
    "    )\n",
    "    noobj_mask_candidates_positives = tf.where(\n",
    "        tf.math.reduce_max(iou_predictions_gt,\n",
    "                           axis=-1) > 0.5, # ignore_threshold\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "    noobj_mask = tf.cast(noobj_mask_candidates, dtype=INT)\n",
    "    noobj_positives_mask = tf.cast(noobj_mask_candidates_positives, dtype=INT)\n",
    "    noobj_gt = tf.boolean_mask(\n",
    "        tf.cast(\n",
    "            tf.where(\n",
    "                tf.math.reduce_max(iou_predictions_gt, axis=-1) > 0.5, 1.0, 0.0\n",
    "            ),\n",
    "            dtype=FLOAT\n",
    "        ),\n",
    "        noobj_mask\n",
    "    )\n",
    "    noobj_positives_gt = tf.boolean_mask(\n",
    "        tf.cast(noobj_positives_mask, FLOAT),\n",
    "        noobj_positives_mask\n",
    "    )\n",
    "    noobj_predictions = tf.boolean_mask(tf.reshape(predicted_objectness, [-1]),\n",
    "                                       noobj_mask)\n",
    "    noobj_positives_predictions = tf.boolean_mask(\n",
    "        tf.reshape(predicted_objectness, [-1]),\n",
    "        noobj_positives_mask\n",
    "    )\n",
    "    print(\"noobj positives\")\n",
    "    print(noobj_positives_predictions)\n",
    "    print(\"\")\n",
    "    print(\"noobj positives iou\")\n",
    "    print(tf.boolean_mask(iou_predictions_gt, noobj_mask_candidates_positives))\n",
    "    print(\"\")\n",
    "\n",
    "    # get BCE Loss for no objectness\n",
    "    noobj_loss = get_noobj_loss(loss_map, noobj_gt, noobj_predictions)\n",
    "    print(\"negative noobj_loss: {}\".format(noobj_loss))\n",
    "    if tf.reduce_any(iou_predictions_gt > 0.5):\n",
    "        noobj_loss_pos = get_noobj_loss(loss_map, noobj_positives_gt, noobj_positives_predictions)\n",
    "        print(\"positive noobj_loss: {}\".format(noobj_loss_pos))\n",
    "        noobj_loss = noobj_loss + noobj_loss_pos\n",
    "\n",
    "    print(\"total noobj_loss: {}\".format(noobj_loss))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Objectness\n",
    "    objectness_predictions = tf.gather_nd(predicted_objectness,\n",
    "                                          prior_indices)\n",
    "    objectness_gt = tf.ones_like(objectness_predictions)\n",
    "    # get BCE Loss for objectness\n",
    "    if valid_matches:\n",
    "        obj_loss = get_obj_loss(loss_map, objectness_gt, objectness_predictions)\n",
    "    else:\n",
    "        obj_loss = tf.constant(0.0)\n",
    "    print(\"obj loss: {}\".format(obj_loss))\n",
    "    print(\"objectness prediction\")\n",
    "    print(\"\")\n",
    "    print(objectness_predictions)\n",
    "    print(\"objectness gt\")\n",
    "    print(objectness_gt)\n",
    "    print(\"\")\n",
    "\n",
    "    # bce loss for classes\n",
    "    class_predictions = tf.gather_nd(predicted_classes, prior_indices)\n",
    "    class_gt = ground_truth_classes_onehot\n",
    "    # get bce loss for classes\n",
    "    if valid_matches:\n",
    "        class_loss = get_class_loss(loss_map, class_gt, class_predictions)\n",
    "    else:\n",
    "        class_loss = tf.constant(0.0)\n",
    "    print(\"class_loss: {}\".format(class_loss))\n",
    "    print(\"class predictions: {}\".format(class_predictions))\n",
    "    print(\"class gt: {}\".format(class_gt))\n",
    "    print(\"\")\n",
    "\n",
    "    # final losses per detection grid\n",
    "    losses['regression_loss'] = localization_loss * 1.0 # scale\n",
    "    losses['objectness_loss'] = obj_loss * 1.0 # scale\n",
    "    losses['noobjectness_loss'] = noobj_loss * 1.0 # scale\n",
    "    losses['classification_loss'] = class_loss * 1.0 # scale\n",
    "    losses['total_loss'] = losses['regression_loss'] + \\\n",
    "        losses['objectness_loss'] + \\\n",
    "        losses['noobjectness_loss'] + \\\n",
    "        losses['classification_loss']\n",
    "\n",
    "    losses['valid'] = valid_matches\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def detection_loss(detection_outputs,\n",
    "                   ground_truth,\n",
    "                   batch_size,\n",
    "                   image_height,\n",
    "                   image_width,\n",
    "                   num_classes,\n",
    "                   anchors_list):\n",
    "    \"\"\"detection_loss.\n",
    "\n",
    "    :param detection_outputs:\n",
    "    :param ground_truth:\n",
    "    :param batch_size:\n",
    "    :param image_height:\n",
    "    :param image_width:\n",
    "    :param num_classes:\n",
    "    :param anchors_list:\n",
    "    \"\"\"\n",
    "    # check detection output is list\n",
    "    assert type(detection_outputs) == list, \"detection_outputs\" \\\n",
    "        \"type {} is not of type list\".format(type(detection_outputs))\n",
    "    # check size of list of anchors is equal to length of detection outputs\n",
    "    # i.e. 3 anchors and 3 detection_outputs.\n",
    "    assert len(detection_outputs) == len(anchors_list), \\\n",
    "        \"Number of outputs from detection_outputs({})\" \\\n",
    "        \"is not equal to anchors_list({})\".format(len(detection_outputs),\n",
    "                                                  len(anchors_list))\n",
    "    # check each detection output tensor is a rank 4 tensor\n",
    "    # [batch_index, grid_x, grid_y, num_classes + 5]\n",
    "    for detection_output in detection_outputs:\n",
    "        assert len(detection_output.shape) == 4, \\\n",
    "            \"detection_outputs member not in shape.\"\\\n",
    "            \"Has shape {}\".format(detection_output.shape)\n",
    "\n",
    "    # get some required tensors\n",
    "    # grid_shapes\n",
    "    grid_shapes = get_grid_shapes(detection_outputs)\n",
    "\n",
    "    current_loss_map = {\n",
    "        'mse' : tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.SUM\n",
    "        ),\n",
    "        'bce' : tf.keras.losses.BinaryCrossentropy(\n",
    "            reduction=tf.keras.losses.Reduction.SUM\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    print(\"ground truth\")\n",
    "    print(ground_truth)\n",
    "\n",
    "    detection_losses = []\n",
    "    for detection_index, detection_output in enumerate(detection_outputs):\n",
    "        current_detection_loss = get_loss_per_grid_detection(detection_output,\n",
    "                                                             current_loss_map,\n",
    "                                                             ground_truth,\n",
    "                                                             anchors_list[detection_index],\n",
    "                                                             grid_shapes[detection_index],\n",
    "                                                             (image_width, image_height),\n",
    "                                                             batch_size,\n",
    "                                                             num_classes)\n",
    "        detection_losses.append(current_detection_loss)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for detection_loss in detection_losses:\n",
    "        total_loss += detection_loss['total_loss']\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_file = \"/home/karan/knapanda_local/playground/yolov3-tf2/cfg/darknet.cfg\"\n",
    "parsed_config = config_parser.parse(model_config_file)\n",
    "training_config = config_reader.reader(\"/home/karan/knapanda_local/playground/yolov3-tf2/cfg/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = dataloader.tf_dataloader(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth\n",
      "tf.Tensor([[0.         0.50961536 0.5168269  0.46875    0.5769231  0.        ]], shape=(1, 6), dtype=float32)\n",
      "anchors: [[116, 90], [156, 198], [373, 326]]\n",
      "grid_x 13, grid_y 13\n",
      "\n",
      "iou(anchors, gt)\n",
      "tf.Tensor([[0.22307692 0.66       0.38487476]], shape=(1, 3), dtype=float32)\n",
      "\n",
      "max iou anchor indices per gt\n",
      "tf.Tensor([1], shape=(1,), dtype=int32)\n",
      "\n",
      "prior indices\n",
      "tf.Tensor([[0 1 6 6]], shape=(1, 4), dtype=int32)\n",
      "\n",
      "priors from preds\n",
      "tf.Tensor([[ 0.09283789  0.06648786 -0.00249639  0.10418341]], shape=(1, 4), dtype=float32)\n",
      "\n",
      "convert gt\n",
      "tf.Tensor([[0.6249995  0.71875    0.22314355 0.19237192]], shape=(1, 4), dtype=float32)\n",
      "\n",
      "localization loss: 0.19183313846588135\n",
      "noobj positives\n",
      "tf.Tensor([0.48794723 0.48634169 0.48297265 0.44670057 0.55757374 0.54828864], shape=(6,), dtype=float32)\n",
      "\n",
      "noobj positives iou\n",
      "tf.Tensor(\n",
      "[[0.52785397]\n",
      " [0.73064435]\n",
      " [0.5368441 ]\n",
      " [0.5300749 ]\n",
      " [0.5039027 ]\n",
      " [0.50587183]], shape=(6, 1), dtype=float32)\n",
      "\n",
      "negative noobj_loss: 0.6979325413703918\n",
      "positive noobj_loss: 0.6928610801696777\n",
      "total noobj_loss: 1.3907935619354248\n",
      "\n",
      "obj loss: 0.7208436727523804\n",
      "objectness prediction\n",
      "\n",
      "tf.Tensor([0.48634169], shape=(1,), dtype=float32)\n",
      "objectness gt\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "\n",
      "class_loss: 0.6920014023780823\n",
      "class predictions: [[0.5005731]]\n",
      "class gt: [[1.]]\n",
      "\n",
      "anchors: [[30, 61], [62, 45], [59, 119]]\n",
      "grid_x 26, grid_y 26\n",
      "\n",
      "iou(anchors, gt)\n",
      "tf.Tensor([[0.03910256 0.05961539 0.15002137]], shape=(1, 3), dtype=float32)\n",
      "\n",
      "max iou anchor indices per gt\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "\n",
      "prior indices\n",
      "tf.Tensor([[ 0  2 13 13]], shape=(1, 4), dtype=int32)\n",
      "\n",
      "priors from preds\n",
      "tf.Tensor([[ 0.13791978  0.01152994 -0.08075857  0.06045878]], shape=(1, 4), dtype=float32)\n",
      "\n",
      "convert gt\n",
      "tf.Tensor([[0.24999905 0.4375     1.1954621  0.7015155 ]], shape=(1, 4), dtype=float32)\n",
      "\n",
      "localization loss: 0.0\n",
      "noobj positives\n",
      "tf.Tensor([], shape=(0,), dtype=float32)\n",
      "\n",
      "noobj positives iou\n",
      "tf.Tensor([], shape=(0, 1), dtype=float32)\n",
      "\n",
      "negative noobj_loss: 0.7103410959243774\n",
      "total noobj_loss: 0.7103410959243774\n",
      "\n",
      "obj loss: 0.0\n",
      "objectness prediction\n",
      "\n",
      "tf.Tensor([0.49031976], shape=(1,), dtype=float32)\n",
      "objectness gt\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "\n",
      "class_loss: 0.0\n",
      "class predictions: [[0.48502958]]\n",
      "class gt: [[1.]]\n",
      "\n",
      "anchors: [[10, 13], [16, 30], [33, 32]]\n",
      "grid_x 52, grid_y 52\n",
      "\n",
      "iou(anchors, gt)\n",
      "tf.Tensor([[0.00277778 0.01025641 0.0225641 ]], shape=(1, 3), dtype=float32)\n",
      "\n",
      "max iou anchor indices per gt\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "\n",
      "prior indices\n",
      "tf.Tensor([[ 0  2 26 26]], shape=(1, 4), dtype=int32)\n",
      "\n",
      "priors from preds\n",
      "tf.Tensor([[0.00211415 0.02439606 0.01535951 0.03972044]], shape=(1, 4), dtype=float32)\n",
      "\n",
      "convert gt\n",
      "tf.Tensor([[0.4999981 0.875     1.776492  2.014903 ]], shape=(1, 4), dtype=float32)\n",
      "\n",
      "localization loss: 0.0\n",
      "noobj positives\n",
      "tf.Tensor([], shape=(0,), dtype=float32)\n",
      "\n",
      "noobj positives iou\n",
      "tf.Tensor([], shape=(0, 1), dtype=float32)\n",
      "\n",
      "negative noobj_loss: 0.6786108613014221\n",
      "total noobj_loss: 0.6786108613014221\n",
      "\n",
      "obj loss: 0.0\n",
      "objectness prediction\n",
      "\n",
      "tf.Tensor([0.48277146], shape=(1,), dtype=float32)\n",
      "objectness gt\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "\n",
      "class_loss: 0.0\n",
      "class predictions: [[0.49941817]]\n",
      "class gt: [[1.]]\n",
      "\n",
      "iter 0, Loss: 4.384423732757568\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karan/.virtualenvs/tf-2.3.1/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 10\n",
    "buffer_size = 1000\n",
    "batch_counter = 0\n",
    "batch_images = []\n",
    "batch_labels = []\n",
    "\n",
    "detection_model = Detector(parsed_config, 1)\n",
    "detection_model = detection_model.build_model((416, 416, 3))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "   learning_rate = 0.0001,\n",
    "   momentum = 0.8\n",
    ")\n",
    "saver = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                           model=detection_model)\n",
    "\n",
    "epoch_template = (\"Epoch {}, Loss: {}\")\n",
    "iter_template = (\"iter {}, Loss: {}\")\n",
    "\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "    total_loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = detection_model(images, training=True)\n",
    "        loss = detection_loss(\n",
    "            predictions,\n",
    "            labels,\n",
    "            BATCH_SIZE,\n",
    "            416,\n",
    "            416,\n",
    "            1,\n",
    "            [\n",
    "                [[116,90],[156,198],[373,326]],\n",
    "                [[30,61],[62,45],[59,119]],\n",
    "                [[10,13],[16,30],[33,32]]\n",
    "            ]\n",
    "        )\n",
    "        total_loss = loss #sum([loss['total_loss'] for l in loss])\n",
    "        gradients = tape.gradient(total_loss, detection_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, detection_model.trainable_variables))\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    iteration = 0\n",
    "    loss_per_epoch = 0\n",
    "    for image, label in train_dataset:\n",
    "        if batch_counter == BATCH_SIZE:\n",
    "            b_images, b_labels = dataloader.combine(batch_images, batch_labels)\n",
    "            loss = train_step((b_images, b_labels,))\n",
    "            loss_per_epoch += loss\n",
    "            print(iter_template.format(iteration, loss))\n",
    "            sys.exit(1)\n",
    "            batch_images = [image]\n",
    "            batch_labels = [label]\n",
    "            batch_counter = 1\n",
    "            iteration+=1\n",
    "        elif batch_counter <= BATCH_SIZE:\n",
    "            batch_images.append(image)\n",
    "            batch_labels.append(label)\n",
    "            batch_counter += 1\n",
    "        else:\n",
    "            print(\"Hitting Else\")\n",
    "    print(epoch_template.format(epoch, loss_per_epoch/iteration))\n",
    "    saved_model_dir = (\n",
    "        \"/home/karan/Checkpoint/ckpt\"\n",
    "    )\n",
    "    saver.save(saved_model_dir)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 0.09283789, 0.06648786, -0.00249639, 0.10418341]], dtype=np.float32)\n",
    "y = np.array([[0.6249995, 0.71875, 0.22314355, 0.19237192]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37740386, 0.5168269 , 0.3966346 , 0.5769231 , 0.        ],\n",
       "       [0.7139423 , 0.53365386, 0.3846154 , 0.59134614, 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8759752"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((x - y) * (x - y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
