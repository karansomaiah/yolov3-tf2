{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"Dog\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_json(filepath):\n",
    "    \"\"\"\n",
    "    Will contain\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as filereader:\n",
    "        labelled_data = json.load(filereader)\n",
    "    return labelled_data\n",
    "\n",
    "\n",
    "def annotation_generator(annotations, image_width, image_height, batch_size):\n",
    "    random.shuffle(annotations)\n",
    "    annotation_length = len(annotations)\n",
    "    for annotation_ndx in range(0, annotation_length, batch_size):\n",
    "        batched_images_as_list = []\n",
    "        batched_labels_as_list = []\n",
    "        for batch_index, batch_num in enumerate(range(annotation_ndx, \n",
    "                                                      min(annotation_ndx + batch_size, annotation_length))):\n",
    "            image = Image.open(annotations[batch_num][\"image_path\"])\n",
    "            image = image.resize(size=(image_width, image_height), resample=PIL.Image.LANCZOS)\n",
    "            bboxes = np.array(\n",
    "                [\n",
    "                    [\n",
    "                        bbox[0] / image_width,\n",
    "                        bbox[1] / image_height,\n",
    "                        bbox[2] / image_width,\n",
    "                        bbox[3] / image_height,\n",
    "                    ] \n",
    "                    for bbox in annotations[batch_num][\"bboxes\"]\n",
    "                ]\n",
    "            )\n",
    "            classes = np.array(\n",
    "                [[class_map[class_label]] for class_label in annotations[batch_num][\"classes\"]]\n",
    "            )\n",
    "            label = np.concatenate([bboxes, classes], axis=-1)\n",
    "            batched_labels_as_list.append(\n",
    "                np.concatenate(\n",
    "                    [\n",
    "                        np.expand_dims(np.ones(label.shape[0]) * batch_index, axis=-1),\n",
    "                        label\n",
    "                    ],\n",
    "                    axis=-1\n",
    "                )\n",
    "            )\n",
    "            batched_images_as_list.append(image)\n",
    "        \n",
    "        # combine them\n",
    "        batch_images = np.stack(batched_images_as_list, axis=0)\n",
    "        batch_labels = np.concatenate(batched_labels_as_list, axis=0)\n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "\n",
    "#     images, labels = [], []\n",
    "#     for annotation in annotations:\n",
    "#         image = Image.open(annotation[\"image_path\"])  # read image\n",
    "#         image = image.resize(\n",
    "#             size=(image_width, image_height), resample=PIL.Image.LANCZOS\n",
    "#         )\n",
    "#         bboxes = np.array(\n",
    "#             [\n",
    "#                 [\n",
    "#                     bbox[0] / image_width,\n",
    "#                     bbox[1] / image_height,\n",
    "#                     bbox[2] / image_width,\n",
    "#                     bbox[3] / image_height,\n",
    "#                 ]\n",
    "#                 # [bbox[0]/640, bbox[1]/640, bbox[2]/640, bbox[3]/640]\n",
    "#                 for bbox in annotation[\"bboxes\"]\n",
    "#             ]\n",
    "#         )\n",
    "#         classes = np.array(\n",
    "#             [[class_map[class_label]] for class_label in annotation[\"classes\"]]\n",
    "#         )\n",
    "#         label = np.concatenate([bboxes, classes], axis=-1)\n",
    "#         images.append(image)\n",
    "#         labels.append(label)\n",
    "#     images = images * 10\n",
    "#     labels = labels * 10\n",
    "    \n",
    "#     # batch generator\n",
    "#     l = len(images)\n",
    "#     for ndx in range(0, l, batch_size):\n",
    "#         batch_images = np.stack(images[ndx:min(ndx + batch_size, l)], axis=0)\n",
    "#         labels_stacked = []\n",
    "#         for batch_index, label in enumerate(labels[ndx:min(ndx + batch_size, l)]):\n",
    "#             labels_stacked.append(\n",
    "#                 np.concatenate(\n",
    "#                     [\n",
    "#                         np.expand_dims(np.ones(label.shape[0]) * batch_index, axis=-1),\n",
    "#                         label\n",
    "#                     ],\n",
    "#                     axis=-1\n",
    "#                 )\n",
    "#             )\n",
    "#         batch_labels = np.concatenate(labels_stacked, axis=0)\n",
    "#         yield np.cast[np.float32](batch_images), batch_labels\n",
    "\n",
    "\n",
    "        \n",
    "def combine(images, labels):\n",
    "    images = tf.stack(images, axis=0) / 255.0\n",
    "    labels_list_with_batch = []\n",
    "    for batch_index, label in enumerate(labels):\n",
    "        labels_list_with_batch.append(\n",
    "            tf.concat(\n",
    "                [tf.expand_dims(tf.ones(label.shape[0]) * batch_index, axis=-1), label],\n",
    "                axis=-1,\n",
    "            )   \n",
    "        )\n",
    "    return images, tf.concat(labels_list_with_batch, axis=0)\n",
    "\n",
    "\n",
    "def batch(dataset, batch_size):\n",
    "    batch_size = batch_size\n",
    "    batch = []\n",
    "    for num, (i, l) in enumerate(dataset):\n",
    "        batch.append(num)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if batch:\n",
    "        yield batch        \n",
    "\n",
    "\n",
    "def tf_dataloader(config_filepath):\n",
    "    # Get Values from the config\n",
    "    input_height = config_filepath[\"INPUT_H\"]\n",
    "    input_width = config_filepath[\"INPUT_W\"]\n",
    "    annotation_filename = config_filepath[\"annotation_path\"]\n",
    "    annotations = read_label_json(annotation_filename)\n",
    "    batch_size = 2\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: annotation_generator(\n",
    "            annotations[\"annotations\"][\"train\"] * 100, input_width, input_height, batch_size\n",
    "        ),  \n",
    "        (tf.float32, tf.float32),\n",
    "    )   \n",
    "#     train_dataset = train_dataset.repeat(10)\n",
    "    validation_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: annotation_generator(\n",
    "            annotations[\"annotations\"][\"validation\"]*10, input_width, input_height, batch_size\n",
    "        ),  \n",
    "        (tf.float32, tf.float32),\n",
    "    )   \n",
    "#     validation_dataset = validation_dataset.repeat(10)\n",
    "\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "\n",
    "def tf_dataloader_v2(label_file_path, image_height, image_width):\n",
    "    if label_file_path:\n",
    "        annotations = read_label_json(label_file_path)\n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: annotation_generator(annotations, input_width, input_height),\n",
    "            (tf.float32, tf.float32),\n",
    "        )   \n",
    "        return train_dataset\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cfg/config.json', 'r') as f:\n",
    "    cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v = tf_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a TFRecord Dataset, it's respective parser and then modifying the loss fn accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = \"data/sample/train.json\"\n",
    "validation_json = \"data/sample/validation.json\"\n",
    "\n",
    "train_label = read_label_json(train_json)\n",
    "validation_label = read_label_json(validation_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_w = 416\n",
    "im_h = 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_label in train_label:\n",
    "    filepath = image_label['image_path']\n",
    "    \n",
    "    xmins, ymins, xmaxs, ymaxs = [], [], [], []\n",
    "    for bbox in image_label['bboxes']:\n",
    "        xmins.append(bbox[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature_list(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature_list(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def get_serialized_example(filename, annotation, input_width, input_height):\n",
    "    # image stuff\n",
    "    image = Image.open(filename)\n",
    "    image = image.resize(size=(input_width, input_height),\n",
    "                         resample=PIL.Image.LANCZOS)\n",
    "    image_string = np.array(image).tostring()\n",
    "\n",
    "    # bounding boxes\n",
    "    x_list, y_list, w_list, h_list = [], [], [], []\n",
    "    labels = []\n",
    "\n",
    "    num_labels = len(annotation['classes'])\n",
    "    for label_index in range(num_labels):\n",
    "        bbox = annotation['bboxes'][label_index]\n",
    "        class_label = int(annotation['classes'][label_index])\n",
    "        x, y, w, h = bbox\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "        w_list.append(w)\n",
    "        h_list.append(h)\n",
    "        labels.append(class_label)\n",
    "        \n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(image_string),\n",
    "        'x': _float_feature_list(x_list),\n",
    "        'y': _float_feature_list(y_list),\n",
    "        'w': _float_feature_list(w_list),\n",
    "        'h': _float_feature_list(h_list),\n",
    "        'label': _int64_feature_list(labels)\n",
    "    }))\n",
    "\n",
    "\n",
    "def write_tfrecords(record_path, annotation_dict, input_width, input_height):\n",
    "    \"\"\"\n",
    "    Processes the dictionary containing annotation information\n",
    "    and returns classes dictionary, as well as the annotation\n",
    "    \"\"\"\n",
    "    with tf.io.TFRecordWriter(record_path) as record_writer:        \n",
    "        for annotation_object in annotation_dict:\n",
    "            current_filename = annotation_object[\"image_path\"]\n",
    "            current_annotation = {\n",
    "                \"bboxes\": [\n",
    "                    [\n",
    "                        box[0] / input_height,\n",
    "                        box[1] / input_width,\n",
    "                        box[2] / input_height,\n",
    "                        box[3] / input_width,\n",
    "                    ]\n",
    "                    for box in annotation_object[\"bboxes\"]\n",
    "                ],\n",
    "                \"classes\": [\n",
    "                    class_map[class_label]\n",
    "                    for class_label in annotation_object[\"classes\"]\n",
    "                ],\n",
    "            }\n",
    "            example = get_serialized_example(current_filename,\n",
    "                                             current_annotation,\n",
    "                                             input_width,\n",
    "                                             input_height)\n",
    "            record_writer.write(example.SerializeToString())\n",
    "        print(\"Completed Writing TFRecord {}\".format(record_path))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Writing TFRecord data/sample/train.record\n",
      "Completed Writing TFRecord data/sample/validation.record\n"
     ]
    }
   ],
   "source": [
    "# write train record\n",
    "train_record = \"data/sample/train.record\"\n",
    "write_tfrecords(train_record, train_label, im_w, im_h)\n",
    "\n",
    "# write validation record\n",
    "validation_record = \"data/sample/validation.record\"\n",
    "write_tfrecords(validation_record, validation_label, im_w, im_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Read in the TFRecord paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "# make it better with parallel calls\n",
    "\n",
    "dataset = tf.data.TFRecordDataset([train_record, validation_record])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = 0\n",
    "for d in dataset.take(2):\n",
    "    if cn == 0:\n",
    "        d1 = d\n",
    "        cn+=1\n",
    "    else:\n",
    "        d2 = d\n",
    "        cn+=1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(example):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'x': tf.io.VarLenFeature(tf.float32),\n",
    "        'y': tf.io.VarLenFeature(tf.float32),\n",
    "        'w': tf.io.VarLenFeature(tf.float32),\n",
    "        'h': tf.io.VarLenFeature(tf.float32),\n",
    "        'label': tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single example being decoded\n",
    "d1_parsed = parser(d1)\n",
    "d2_parsed = parser(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting single decoded image into tensor i.e. sparse to dense\n",
    "image = tf.io.decode_raw(input_bytes=d1_parsed['image'], out_type=tf.uint8)\n",
    "image_tensor = tf.expand_dims(tf.reshape(image, (416, 416, 3)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing labels, x, y, w, h\n",
    "labels = tf.cast(tf.sparse.to_dense(d1_parsed['label']), dtype=tf.float32)\n",
    "x = tf.sparse.to_dense(d1_parsed['x'])\n",
    "y = tf.sparse.to_dense(d1_parsed['y'])\n",
    "w = tf.sparse.to_dense(d1_parsed['w'])\n",
    "h = tf.sparse.to_dense(d1_parsed['h'])\n",
    "stacked = tf.stack([x, y, w, h, labels], axis=1)\n",
    "paddings = [[0, 100-tf.shape(stacked)[0]], [0, 0]]\n",
    "l1 = tf.pad(stacked, paddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.io.decode_raw(input_bytes=d2_parsed['image'], out_type=tf.uint8)\n",
    "image_tensor = tf.expand_dims(tf.reshape(image, (416, 416, 3)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.cast(tf.sparse.to_dense(d2_parsed['label']), dtype=tf.float32)\n",
    "x = tf.sparse.to_dense(d2_parsed['x'])\n",
    "y = tf.sparse.to_dense(d2_parsed['y'])\n",
    "w = tf.sparse.to_dense(d2_parsed['w'])\n",
    "h = tf.sparse.to_dense(d2_parsed['h'])\n",
    "stacked = tf.stack([x, y, w, h, labels], axis=1)\n",
    "paddings = [[0, 100-tf.shape(stacked)[0]], [0, 0]]\n",
    "l2 = tf.pad(stacked, paddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100, 5), dtype=float32, numpy=\n",
       " array([[0.50961536, 0.5168269 , 0.46875   , 0.5769231 , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 5), dtype=float32, numpy=\n",
       " array([[0.37740386, 0.5168269 , 0.3966346 , 0.5769231 , 1.        ],\n",
       "        [0.7139423 , 0.53365386, 0.3846154 , 0.59134614, 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 416, 416, 3), dtype=float32, numpy=\n",
       "array([[[[0.23137255, 0.36862746, 0.14901961],\n",
       "         [0.21960784, 0.34901962, 0.14117648],\n",
       "         [0.19215687, 0.31764707, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.09803922, 0.19607843, 0.07843138],\n",
       "         [0.09411765, 0.19215687, 0.07843138],\n",
       "         [0.09411765, 0.19215687, 0.07843138]],\n",
       "\n",
       "        [[0.23529412, 0.37254903, 0.14509805],\n",
       "         [0.21960784, 0.34901962, 0.14117648],\n",
       "         [0.19215687, 0.31764707, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.09803922, 0.19607843, 0.07843138],\n",
       "         [0.09803922, 0.19607843, 0.08235294],\n",
       "         [0.09411765, 0.19215687, 0.07843138]],\n",
       "\n",
       "        [[0.23921569, 0.3764706 , 0.14901961],\n",
       "         [0.22745098, 0.35686275, 0.14901961],\n",
       "         [0.2       , 0.3254902 , 0.13333334],\n",
       "         ...,\n",
       "         [0.10196079, 0.2       , 0.08235294],\n",
       "         [0.09803922, 0.19607843, 0.08235294],\n",
       "         [0.09411765, 0.19215687, 0.07843138]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7176471 , 0.73333335, 0.76862746],\n",
       "         [0.74509805, 0.7607843 , 0.79607844],\n",
       "         [0.7254902 , 0.7372549 , 0.77254903],\n",
       "         ...,\n",
       "         [0.78039217, 0.78431374, 0.8       ],\n",
       "         [0.7764706 , 0.78039217, 0.79607844],\n",
       "         [0.7647059 , 0.76862746, 0.78431374]],\n",
       "\n",
       "        [[0.70980394, 0.7254902 , 0.76862746],\n",
       "         [0.7490196 , 0.7647059 , 0.80784315],\n",
       "         [0.7294118 , 0.7411765 , 0.7764706 ],\n",
       "         ...,\n",
       "         [0.7764706 , 0.78039217, 0.8       ],\n",
       "         [0.7647059 , 0.76862746, 0.7882353 ],\n",
       "         [0.7529412 , 0.75686276, 0.7764706 ]],\n",
       "\n",
       "        [[0.7058824 , 0.72156864, 0.7647059 ],\n",
       "         [0.7490196 , 0.7647059 , 0.80784315],\n",
       "         [0.73333335, 0.74509805, 0.78039217],\n",
       "         ...,\n",
       "         [0.7764706 , 0.7764706 , 0.80784315],\n",
       "         [0.75686276, 0.75686276, 0.7882353 ],\n",
       "         [0.7411765 , 0.7411765 , 0.77254903]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating the loss fn for the new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_list = [[[116,90], [156,198], [373,326]],\n",
    "               [[30,61], [62,45], [59,119]],\n",
    "               [[10,13], [16,30], [33,23]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[116,  90],\n",
       "       [156, 198],\n",
       "       [373, 326]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(anchors_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_0 = np.load('/home/karan/knapanda_local/playground/yolo_outs/out_0.npy')\n",
    "out_1 = np.load('/home/karan/knapanda_local/playground/yolo_outs/out_1.npy')\n",
    "out_2 = np.load('/home/karan/knapanda_local/playground/yolo_outs/out_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_0 = tf.concat([out_0, out_0], axis=0)\n",
    "output_1 = tf.concat([out_1, out_1], axis=0)\n",
    "output_2 = tf.concat([out_2, out_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_0_reshaped = tf.reshape(output_0, [2, 3, 13, 13, 6])\n",
    "output_1_reshaped = tf.reshape(output_1, [2, 3, 26, 26, 6])\n",
    "output_2_reshaped = tf.reshape(output_2, [2, 3, 52, 52, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tf.concat([tf.expand_dims(l1, axis=0), tf.expand_dims(l2, axis=0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_tf(x1, w1, x2, w2):\n",
    "    num_1 = x1.shape[0]\n",
    "    num_2 = x2.shape[0]\n",
    "    x1 = tf.broadcast_to(x1, [num_2, num_1])\n",
    "    w1 = tf.broadcast_to(w1, [num_2, num_1])\n",
    "    x2 = tf.transpose(tf.broadcast_to(x2, [num_1, num_2]))\n",
    "    w2 = tf.transpose(tf.broadcast_to(w2, [num_1, num_2]))\n",
    "    \n",
    "    l1 = x1 - (w1/2)\n",
    "    l2 = x2 - (w2/2)\n",
    "    l = tf.math.maximum(l1, l2)\n",
    "    r1 = x1 + (w1/2)\n",
    "    r2 = x2 + (w2/2)\n",
    "    r = tf.math.minimum(r1, r2)\n",
    "    return r - l\n",
    "\n",
    "def box_intersection_tf(a, b):\n",
    "    w = overlap_tf(a[:, 0], a[:, 2], b[:, 0], b[:, 2])\n",
    "    w = tf.where(tf.math.greater(w, 0.0), w, 0.0)\n",
    "    h = overlap_tf(a[:, 1], a[:, 3], b[:, 1], b[:, 3])\n",
    "    h = tf.where(tf.math.greater(h, 0.0), h, 0.0)\n",
    "    area = w * h\n",
    "    return area\n",
    "\n",
    "def box_union_tf(a, b):\n",
    "    a_num = a.shape[0]\n",
    "    b_num = b.shape[0]\n",
    "    intersection = box_intersection_tf(a, b)\n",
    "    a_w = a[:, 2]\n",
    "    a_h = a[:, 3]\n",
    "    b_w = b[:, 2]\n",
    "    b_h = b[:, 3]\n",
    "    a_w = tf.broadcast_to(a_w, [b_num, a_num])\n",
    "    a_h = tf.broadcast_to(a_h, [b_num, a_num])\n",
    "    b_w = tf.transpose(tf.broadcast_to(b_w, [a_num, b_num]))\n",
    "    b_h = tf.transpose(tf.broadcast_to(b_h, [a_num, b_num]))\n",
    "    union = (a_w * a_h) + (b_w * b_h) - intersection\n",
    "    return union\n",
    "\n",
    "def box_iou_tf(a, b):\n",
    "    return box_intersection_tf(a, b)/box_union_tf(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's consider only output0\n",
    "grid_y_num, grid_x_num = tf.shape(output_0)[1:3]\n",
    "# x - offset\n",
    "intermediate_center_x_offset = tf.broadcast_to(\n",
    "    tf.range(grid_x_num, dtype=tf.float32),\n",
    "    [grid_y_num, grid_x_num]\n",
    ")\n",
    "# center_x_offsets = tf.broadcast_to(\n",
    "#     intermediate_center_x_offset,\n",
    "#     [batch_size, grid_y_num, grid_x_num]\n",
    "# )\n",
    "\n",
    "# y - offsets\n",
    "intermediate_center_y_offset = tf.broadcast_to(\n",
    "    tf.range(grid_y_num, dtype=tf.float32),\n",
    "    [grid_x_num, grid_y_num]\n",
    ")\n",
    "intermediate_center_y_offset = tf.transpose(intermediate_center_y_offset)\n",
    "# center_y_offsets = tf.broadcast_to(\n",
    "#     intermediate_center_y_offset,\n",
    "#     [batch_size, grid_y_num, grid_x_num]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gt = tf.where(label[:, :, -1] == 0.0, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors as tensor\n",
    "current_anchor_index = 0\n",
    "anchor_tensor = tf.constant(anchors_list[0], dtype=tf.float32)\n",
    "batch_size = output_0.shape[0]\n",
    "num_anchors = anchor_tensor.shape[0]\n",
    "\n",
    "# iou computation\n",
    "im_wh = tf.broadcast_to([[416.0, 416.0]], [3, 2]) # image width, height broadcasted to anchor size\n",
    "anchors_norm = anchor_tensor/im_wh # normalize by width,height\n",
    "\n",
    "# wh only\n",
    "anchors_wh = tf.concat(\n",
    "    [tf.zeros_like(anchors_norm[:, :2], dtype=tf.float32), # zeros\n",
    "    anchors_norm[:, :2]], # anchor wh\n",
    "    axis=1\n",
    ")\n",
    "#anchors_wh = tf.broadcast_to(tf.expand_dims(anchors_wh, axis=0), [batch_size, 3, 4])\n",
    "gt_wh = tf.concat(\n",
    "    [\n",
    "        tf.zeros_like(label[:, :, -3:-1]),\n",
    "        label[:, :, -3:-1]\n",
    "    ], \n",
    "    axis=-1\n",
    ")\n",
    "anchors_wh_norm_flattened = tf.reshape(anchors_wh, [-1, 4])\n",
    "gt_wh_norm_flattened = tf.reshape(gt_wh, [-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iou = box_iou_tf(anchors_wh_norm_flattened, gt_wh_norm_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_reshape = tf.reshape(iou, [batch_size, top_k, num_anchors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_argmax_per_anchor = tf.argmax(iou_reshape, axis=-1, output_type=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_anchors = tf.broadcast_to(anchor_tensor, [2, 100, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Loss (Localization Loss)\n",
    "label_noclass = label[:, :, :-1] # only x, y, w, h\n",
    "i_gt = tf.cast(label_noclass[:, :, 0] * tf.cast(grid_x_num, dtype=tf.float32), \n",
    "               dtype=tf.int32)\n",
    "j_gt = tf.cast(label_noclass[:, :, 1] * tf.cast(grid_y_num, dtype=tf.float32), \n",
    "               dtype=tf.int32)\n",
    "batch_broadcasted = tf.broadcast_to(tf.expand_dims(tf.range(2), axis=1), [batch_size, top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_anchor_indices_per_gt = tf.stack(\n",
    "    [batch_broadcasted, \n",
    "     tf.stack([tf.range(100), tf.range(100)]),\n",
    "     iou_argmax_per_anchor\n",
    "    ], axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the anchor w/h selected from the best indices calculated from the iou\n",
    "# size (2, 100, 2)?\n",
    "best_anchors_per_gt = tf.gather_nd(expanded_anchors, best_anchor_indices_per_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices to gather from the outputs\n",
    "indices_to_subset = tf.stack([batch_broadcasted, iou_argmax_per_anchor, j_gt, i_gt], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean mask to only consider gts that are valid and not all 100\n",
    "valid_label_indices = tf.boolean_mask(indices_to_subset, is_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCE Objectness Loss\n",
    "predicted_bboxes = output_0_reshaped[..., :4]\n",
    "predicted_objectness = tf.math.sigmoid(output_0_reshaped[..., 4])\n",
    "predicted_classes = tf.math.sigmoid(output_0_reshaped[..., 5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 13, 13, 1), dtype=float32, numpy=\n",
       "array([[[[[0.47926983],\n",
       "          [0.51614344],\n",
       "          [0.4992844 ],\n",
       "          ...,\n",
       "          [0.5359981 ],\n",
       "          [0.52558875],\n",
       "          [0.4790221 ]],\n",
       "\n",
       "         [[0.53981775],\n",
       "          [0.5264706 ],\n",
       "          [0.47973907],\n",
       "          ...,\n",
       "          [0.52938604],\n",
       "          [0.47787607],\n",
       "          [0.5358088 ]],\n",
       "\n",
       "         [[0.52761084],\n",
       "          [0.48422247],\n",
       "          [0.53768736],\n",
       "          ...,\n",
       "          [0.5018741 ],\n",
       "          [0.5229705 ],\n",
       "          [0.51987016]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.49683288],\n",
       "          [0.5177637 ],\n",
       "          [0.48948792],\n",
       "          ...,\n",
       "          [0.51220363],\n",
       "          [0.48012853],\n",
       "          [0.49885696]],\n",
       "\n",
       "         [[0.5163    ],\n",
       "          [0.48162195],\n",
       "          [0.49557665],\n",
       "          ...,\n",
       "          [0.49975002],\n",
       "          [0.5144084 ],\n",
       "          [0.49003065]],\n",
       "\n",
       "         [[0.48536378],\n",
       "          [0.4932135 ],\n",
       "          [0.5224819 ],\n",
       "          ...,\n",
       "          [0.49316624],\n",
       "          [0.5235805 ],\n",
       "          [0.4895051 ]]],\n",
       "\n",
       "\n",
       "        [[[0.49885362],\n",
       "          [0.51712465],\n",
       "          [0.48181173],\n",
       "          ...,\n",
       "          [0.5158919 ],\n",
       "          [0.48838606],\n",
       "          [0.49557102]],\n",
       "\n",
       "         [[0.52088255],\n",
       "          [0.48635647],\n",
       "          [0.49521187],\n",
       "          ...,\n",
       "          [0.5038573 ],\n",
       "          [0.5078261 ],\n",
       "          [0.4890507 ]],\n",
       "\n",
       "         [[0.4840095 ],\n",
       "          [0.49587205],\n",
       "          [0.5241401 ],\n",
       "          ...,\n",
       "          [0.49765942],\n",
       "          [0.52886677],\n",
       "          [0.48617357]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.5163946 ],\n",
       "          [0.48237586],\n",
       "          [0.48994493],\n",
       "          ...,\n",
       "          [0.5021187 ],\n",
       "          [0.51331335],\n",
       "          [0.49227858]],\n",
       "\n",
       "         [[0.48467413],\n",
       "          [0.49640647],\n",
       "          [0.52289206],\n",
       "          ...,\n",
       "          [0.4935108 ],\n",
       "          [0.51960295],\n",
       "          [0.48185843]],\n",
       "\n",
       "         [[0.4953471 ],\n",
       "          [0.52134037],\n",
       "          [0.47830468],\n",
       "          ...,\n",
       "          [0.5211808 ],\n",
       "          [0.48830312],\n",
       "          [0.4956314 ]]],\n",
       "\n",
       "\n",
       "        [[[0.524763  ],\n",
       "          [0.4763614 ],\n",
       "          [0.49118736],\n",
       "          ...,\n",
       "          [0.5011861 ],\n",
       "          [0.5145846 ],\n",
       "          [0.49212077]],\n",
       "\n",
       "         [[0.48013034],\n",
       "          [0.5020027 ],\n",
       "          [0.5287806 ],\n",
       "          ...,\n",
       "          [0.49726665],\n",
       "          [0.5168557 ],\n",
       "          [0.4961643 ]],\n",
       "\n",
       "         [[0.48943138],\n",
       "          [0.5206853 ],\n",
       "          [0.49349445],\n",
       "          ...,\n",
       "          [0.51580244],\n",
       "          [0.4909675 ],\n",
       "          [0.49177238]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.49524534],\n",
       "          [0.4763681 ],\n",
       "          [0.5344478 ],\n",
       "          ...,\n",
       "          [0.46237466],\n",
       "          [0.51820475],\n",
       "          [0.50561637]],\n",
       "\n",
       "         [[0.4627507 ],\n",
       "          [0.5170784 ],\n",
       "          [0.5020125 ],\n",
       "          ...,\n",
       "          [0.51382643],\n",
       "          [0.5070893 ],\n",
       "          [0.4622504 ]],\n",
       "\n",
       "         [[0.50858665],\n",
       "          [0.5106673 ],\n",
       "          [0.46686167],\n",
       "          ...,\n",
       "          [0.49848077],\n",
       "          [0.49652317],\n",
       "          [0.4793111 ]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.47926983],\n",
       "          [0.51614344],\n",
       "          [0.4992844 ],\n",
       "          ...,\n",
       "          [0.5359981 ],\n",
       "          [0.52558875],\n",
       "          [0.4790221 ]],\n",
       "\n",
       "         [[0.53981775],\n",
       "          [0.5264706 ],\n",
       "          [0.47973907],\n",
       "          ...,\n",
       "          [0.52938604],\n",
       "          [0.47787607],\n",
       "          [0.5358088 ]],\n",
       "\n",
       "         [[0.52761084],\n",
       "          [0.48422247],\n",
       "          [0.53768736],\n",
       "          ...,\n",
       "          [0.5018741 ],\n",
       "          [0.5229705 ],\n",
       "          [0.51987016]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.49683288],\n",
       "          [0.5177637 ],\n",
       "          [0.48948792],\n",
       "          ...,\n",
       "          [0.51220363],\n",
       "          [0.48012853],\n",
       "          [0.49885696]],\n",
       "\n",
       "         [[0.5163    ],\n",
       "          [0.48162195],\n",
       "          [0.49557665],\n",
       "          ...,\n",
       "          [0.49975002],\n",
       "          [0.5144084 ],\n",
       "          [0.49003065]],\n",
       "\n",
       "         [[0.48536378],\n",
       "          [0.4932135 ],\n",
       "          [0.5224819 ],\n",
       "          ...,\n",
       "          [0.49316624],\n",
       "          [0.5235805 ],\n",
       "          [0.4895051 ]]],\n",
       "\n",
       "\n",
       "        [[[0.49885362],\n",
       "          [0.51712465],\n",
       "          [0.48181173],\n",
       "          ...,\n",
       "          [0.5158919 ],\n",
       "          [0.48838606],\n",
       "          [0.49557102]],\n",
       "\n",
       "         [[0.52088255],\n",
       "          [0.48635647],\n",
       "          [0.49521187],\n",
       "          ...,\n",
       "          [0.5038573 ],\n",
       "          [0.5078261 ],\n",
       "          [0.4890507 ]],\n",
       "\n",
       "         [[0.4840095 ],\n",
       "          [0.49587205],\n",
       "          [0.5241401 ],\n",
       "          ...,\n",
       "          [0.49765942],\n",
       "          [0.52886677],\n",
       "          [0.48617357]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.5163946 ],\n",
       "          [0.48237586],\n",
       "          [0.48994493],\n",
       "          ...,\n",
       "          [0.5021187 ],\n",
       "          [0.51331335],\n",
       "          [0.49227858]],\n",
       "\n",
       "         [[0.48467413],\n",
       "          [0.49640647],\n",
       "          [0.52289206],\n",
       "          ...,\n",
       "          [0.4935108 ],\n",
       "          [0.51960295],\n",
       "          [0.48185843]],\n",
       "\n",
       "         [[0.4953471 ],\n",
       "          [0.52134037],\n",
       "          [0.47830468],\n",
       "          ...,\n",
       "          [0.5211808 ],\n",
       "          [0.48830312],\n",
       "          [0.4956314 ]]],\n",
       "\n",
       "\n",
       "        [[[0.524763  ],\n",
       "          [0.4763614 ],\n",
       "          [0.49118736],\n",
       "          ...,\n",
       "          [0.5011861 ],\n",
       "          [0.5145846 ],\n",
       "          [0.49212077]],\n",
       "\n",
       "         [[0.48013034],\n",
       "          [0.5020027 ],\n",
       "          [0.5287806 ],\n",
       "          ...,\n",
       "          [0.49726665],\n",
       "          [0.5168557 ],\n",
       "          [0.4961643 ]],\n",
       "\n",
       "         [[0.48943138],\n",
       "          [0.5206853 ],\n",
       "          [0.49349445],\n",
       "          ...,\n",
       "          [0.51580244],\n",
       "          [0.4909675 ],\n",
       "          [0.49177238]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.49524534],\n",
       "          [0.4763681 ],\n",
       "          [0.5344478 ],\n",
       "          ...,\n",
       "          [0.46237466],\n",
       "          [0.51820475],\n",
       "          [0.50561637]],\n",
       "\n",
       "         [[0.4627507 ],\n",
       "          [0.5170784 ],\n",
       "          [0.5020125 ],\n",
       "          ...,\n",
       "          [0.51382643],\n",
       "          [0.5070893 ],\n",
       "          [0.4622504 ]],\n",
       "\n",
       "         [[0.50858665],\n",
       "          [0.5106673 ],\n",
       "          [0.46686167],\n",
       "          ...,\n",
       "          [0.49848077],\n",
       "          [0.49652317],\n",
       "          [0.4793111 ]]]]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_index = 0\n",
    "h_index = 1\n",
    "w_offsets = tf.broadcast_to(tf.expand_dims(tf.broadcast_to(tf.expand_dims(tf.broadcast_to(tf.expand_dims(anchor_tensor[:, w_index], axis=-1), [num_anchors, grid_y_num]), axis=-1), [num_anchors, grid_y_num, grid_x_num]), axis=0), [batch_size, num_anchors, grid_y_num, grid_x_num])\n",
    "h_offsets = tf.broadcast_to(tf.expand_dims(tf.broadcast_to(tf.expand_dims(tf.broadcast_to(tf.expand_dims(anchor_tensor[:, h_index], axis=-1), [num_anchors, grid_y_num]), axis=-1), [num_anchors, grid_y_num, grid_x_num]), axis=0), [batch_size, num_anchors, grid_y_num, grid_x_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_x_offsets = tf.broadcast_to(\n",
    "    intermediate_center_x_offset,\n",
    "    [batch_size, num_anchors, grid_y_num, grid_x_num]\n",
    ")\n",
    "center_y_offsets = tf.broadcast_to(\n",
    "    intermediate_center_y_offset,\n",
    "    [batch_size, num_anchors, grid_y_num, grid_x_num]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = tf.math.sigmoid(predicted_bboxes[..., 0])\n",
    "pred_y = tf.math.sigmoid(predicted_bboxes[..., 1])\n",
    "pred_w = predicted_bboxes[..., 2]\n",
    "pred_h = predicted_bboxes[..., 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = (pred_x + center_x_offsets)/tf.cast(grid_x_num, dtype=tf.float32)\n",
    "predicted_y = (pred_y + center_y_offsets)/tf.cast(grid_y_num, dtype=tf.float32)\n",
    "predicted_w = tf.exp(pred_w) * (w_offsets/416.0)\n",
    "predicted_h = tf.exp(pred_h) * (h_offsets/416.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bb = tf.stack([\n",
    "    predicted_x,\n",
    "    predicted_y,\n",
    "    predicted_w,\n",
    "    predicted_h\n",
    "],\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered_outputs = tf.gather_nd(predictions_bb, valid_label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create gt predictions\n",
    "gt_tx = (label_noclass[..., 0] * tf.cast(grid_x_num, tf.float32)) - tf.cast(i_gt, tf.float32)\n",
    "gt_ty = (label_noclass[..., 1] * tf.cast(grid_y_num, tf.float32)) - tf.cast(j_gt, tf.float32)\n",
    "gt_tw = tf.math.log(label_noclass[..., 2] * 416.0/best_anchors_per_gt[...,0])\n",
    "gt_th = tf.math.log(label_noclass[..., 2] * 416.0/best_anchors_per_gt[...,1])\n",
    "gt_all = tf.stack([\n",
    "    gt_tx,\n",
    "    gt_ty,\n",
    "    gt_tw,\n",
    "    gt_th\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ground truth bounding boxes for valid bb\n",
    "gt_boundingboxes = tf.boolean_mask(gt_all, is_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.54535985>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "mse_loss(gt_boundingboxes, gathered_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_preds_iou = box_iou_tf(\n",
    "#     label_noclass_flattened,\n",
    "#     flattened_predictions_bb\n",
    "# )\n",
    "\n",
    "# @why\n",
    "# converting the above calculation into a map_fn to reduce redundancy from for loops.\n",
    "# tf.map_fn internally parallelizes the map call.\n",
    "# it's definitely not as fast as a vectorized operation\n",
    "# but reduces the creation of intermediate, non-reusable tensors\n",
    "\n",
    "# predictions_bb is of shape (batch_size, anchor_size, grid_y, grid_x, ... (4))\n",
    "# hence, the reshape is required and it's reshaped on output\n",
    "\n",
    "# gt_preds_iou = tf.map_fn(\n",
    "#     lambda x: tf.reshape(box_iou_tf(x[0], x[1]),\n",
    "#                         [num_anchors, grid_y_num, grid_x_num, top_k]),\n",
    "#     elems=(label_noclass,\n",
    "#            tf.reshape(predictions_bb, [2, -1, 4])),\n",
    "#     dtype=(tf.float32, tf.float32),\n",
    "#     fn_output_signature=tf.float32\n",
    "# )\n",
    "\n",
    "# WE DON'T NEED TO DO THIS. REFERRING TO DetectionLoss in yolo code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.22307692, 0.66      , 0.38487476],\n",
       "       [0.26363638, 0.78000003, 0.3256632 ],\n",
       "       [0.2652439 , 0.78475606, 0.32368952]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.boolean_mask(tf.reshape(iou, [2, 100, 3]), is_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pos = tf.where(\n",
    "    iou_reshape > 0.5,\n",
    ")\n",
    "\n",
    "# the output of this gives [batch_index, gt_index, anchor_index]\n",
    "# batch_index, gt_index is the indexing for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices to get candidate positives\n",
    "batch_index = tf.cast(candidate_pos[:, 0], dtype=tf.int32)\n",
    "gt_index_per_batch = tf.cast(candidate_pos[:, 1], dtype=tf.int32)\n",
    "anchor_index_per_candidate = tf.cast(candidate_pos[:, 2], dtype=tf.int32)\n",
    "\n",
    "batch_gt_per_candidate = tf.cast(candidate_pos[:, :2], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pos_x = tf.gather_nd(i_gt, batch_gt_per_candidate)\n",
    "candidate_pos_y = tf.gather_nd(j_gt, batch_gt_per_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate positive indices\n",
    "candidate_positives = tf.stack(\n",
    "    [\n",
    "        batch_index,\n",
    "        anchor_index_per_candidate,\n",
    "        candidate_pos_y,\n",
    "        candidate_pos_x\n",
    "    ],\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above list is appeneded with the ground truth one \n",
    "# since they are objects too (you know :')). \n",
    "# And this combined list will have some duplicates which will have\n",
    "# values greater than 1 when applied with scatter_nd.\n",
    "# this is rectified to 1\n",
    "pos_concat = tf.concat([candidate_positives, valid_label_indices], axis=0)\n",
    "obj_gt_vals = tf.ones_like(pos_concat[:, 0], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectness_mask = tf.scatter_nd(\n",
    "    pos_concat,\n",
    "    obj_gt_vals,\n",
    "    [2, 3, 13, 13]\n",
    ")\n",
    "objectness_mask = tf.where(objectness_mask != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectness_indices = tf.where(objectness_mask != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectness_float = tf.cast(objectness_mask, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_objectness = tf.gather_nd(predicted_objectness, objectness_indices)\n",
    "gt_objectness = tf.boolean_mask(objectness_float, objectness_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "objectness_loss = bce(gt_objectness, pred_objectness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCE Classification Loss\n",
    "noobj_mask = tf.cast(tf.logical_not(tf.cast(objectness_mask, dtype=tf.bool)), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "noobj_indices = tf.where(noobj_mask != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_noobj = tf.gather_nd(predicted_objectness, noobj_indices)\n",
    "gt_noobj = tf.boolean_mask(objectness_float, noobj_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1011,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_noobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "noobjectness_loss = bce(gt_noobj, pred_noobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6643688>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noobjectness_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.boolean_mask(label, is_gt)[:, -1], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_gt_class_indices = tf.concat([valid_label_indices, tf.expand_dims(tf.cast(tf.boolean_mask(label, is_gt)[:, -1], dtype=tf.int32), axis=-1)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_preds_classes = tf.concat([predicted_classes, predicted_classes], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[0, 1, 6, 6, 0],\n",
       "       [1, 1, 6, 4, 1],\n",
       "       [1, 1, 6, 9, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_gt_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_classes = tf.gather_nd(dummy_preds_classes, dummy_gt_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_classes = tf.ones_like(preds_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6844391>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce(gt_classes, preds_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at batch 6 and batch 11 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/karan/batch6_tl_data.json', 'r') as f:\n",
    "    batch6 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/karan/batch12_tl_data.json', 'r') as f:\n",
    "    batch12 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sample/label.json', 'r')as f:\n",
    "    yolov3_sample_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TrafficLight-NotVisible': [{'p1': {'x': 282.013351051628, 'y': 348.38909748027027}, 'p2': {'x': 294.94974646119493, 'y': 380.0345544323436}}, {'p1': {'x': 1213.0695722013738, 'y': 95.67767034449548}, 'p2': {'x': 1248.7721122263304, 'y': 186.5342678826389}}, {'p1': {'x': 1173.2873455978736, 'y': 173.32215153121493}, 'p2': {'x': 1201.8337740357058, 'y': 245.12734416547283}}, {'p1': {'x': 456.37739981428615, 'y': 435.4329556136607}, 'p2': {'x': 467.3436508346806, 'y': 443.9970547837003}}], 'filename': 'runs_data/northEnd291Ray/TLImages_1599844978/Pedestrian_Light_00000000-0000-0000-0000-000000009350/1599849483.png', 'full_path': '/mnt/KiwiFTP/kiwi_transfer/hive_data/images_sent/batch_12/runs_data/northEnd291Ray/TLImages_1599844978/Pedestrian_Light_00000000-0000-0000-0000-000000009350/1599849483.png', 'TrafficLight-Off': [], 'TrafficLight-Red': [{'p1': {'x': 110.12370594621925, 'y': 304.745441860671}, 'p2': {'x': 123.76888660763292, 'y': 338.74308435489}}, {'p1': {'x': 184.07765365908034, 'y': 322.95688738995733}, 'p2': {'x': 197.5335425148738, 'y': 352.6584101057315}}, {'p1': {'x': 246.14279616230988, 'y': 338.4124033417585}, 'p2': {'x': 258.5449981055946, 'y': 363.62851447346776}}, {'p1': {'x': 732.4245360484894, 'y': 372.9024428867694}, 'p2': {'x': 744.388483477108, 'y': 397.5680581086401}}], 'TrafficLight-RedLeft': [], 'TrafficLight-RedRight': [], 'TrafficLight-RedStraight': [], 'TrafficLight-Yellow': [], 'TrafficLight-Green': [{'p1': {'x': 794.1926990701566, 'y': 373.0540691972209}, 'p2': {'x': 805.5188551302094, 'y': 396.60966164520414}}], 'TrafficLight-GreenLeft': [], 'TrafficLight-GreenRight': [{'p1': {'x': 903.5567944118276, 'y': 371.6824205115002}, 'p2': {'x': 915.1969125499395, 'y': 402.70245908422544}}], 'TrafficLight-GreenStraight': [{'p1': {'x': 856.5924772234571, 'y': 371.2133757262335}, 'p2': {'x': 868.2219975206026, 'y': 396.7850401721861}}], 'PedestrianLight-Walk': [], 'PedestrianLight-NoWalk': [{'p1': {'x': 441.86426363578363, 'y': 434.07338194839866}, 'p2': {'x': 451.49861509364064, 'y': 443.34601311703364}}, {'p1': {'x': 1046.3819735210286, 'y': 431.60805680185683}, 'p2': {'x': 1056.7837122985252, 'y': 443.37250156786166}}]}\n"
     ]
    }
   ],
   "source": [
    "print(batch12[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': {'Dog': 0}, 'annotations': {'train': [{'image_path': 'data/sample/dog.jpg', 'bboxes': [[212, 215, 195, 240]], 'classes': ['Dog']}, {'image_path': 'data/sample/dog2.jpg', 'bboxes': [[157, 215, 165, 240], [297, 222, 160, 246]], 'classes': ['Dog', 'Dog']}], 'validation': [{'image_path': 'data/sample/dog.jpg', 'bboxes': [[212, 215, 195, 240]], 'classes': ['Dog']}, {'image_path': 'data/sample/dog2.jpg', 'bboxes': [[157, 215, 165, 240], [297, 222, 160, 246]], 'classes': ['Dog', 'Dog']}]}}\n"
     ]
    }
   ],
   "source": [
    "print(yolov3_sample_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a new train dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = {}\n",
    "new_train = []\n",
    "new_validation = []\n",
    "new_classmap = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_keys = ['filename', 'full_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_light_labels = list(filter(lambda x: x not in unnecessary_keys, batch12[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_light_class_integer_map = {\n",
    "    label: label_index + 1 for label_index, label in enumerate(traffic_light_labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotation in batch12:\n",
    "    img_path = annotation['full_path']\n",
    "    classes = []\n",
    "    bboxes = []\n",
    "    converted_annotation = {}\n",
    "    for class_label in traffic_light_labels:\n",
    "        class_label_labels = annotation[class_label]\n",
    "        for bbox in class_label_labels:\n",
    "            x1 = (bbox['p1']['x']/1280)*416\n",
    "            y1 = (bbox['p1']['y']/800)*416\n",
    "            x2 = (bbox['p2']['x']/1280)*416\n",
    "            y2 = (bbox['p2']['y']/800)*416\n",
    "            x = int((x1 + x2)/2)\n",
    "            y = int((y1 + y2)/2)\n",
    "            w = int(x2 - x1)\n",
    "            h = int(y2 - y1)\n",
    "            bboxes.append([x, y, w, h])\n",
    "            classes.append(class_label)\n",
    "    converted_annotation['img_path'] = img_path\n",
    "    converted_annotation['classes'] = classes\n",
    "    converted_annotation['bboxes'] = bboxes\n",
    "    \n",
    "    new_train.append(converted_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spit to train and validation\n",
    "import random\n",
    "random.shuffle(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_validation = new_train[-int(len(new_train)*0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = new_train[:-int(len(new_train)*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35410\n",
      "8852\n"
     ]
    }
   ],
   "source": [
    "print(len(new_train))\n",
    "print(len(new_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = {\n",
    "    'classes': traffic_light_class_integer_map,\n",
    "    'annotations': {\n",
    "        'train': new_train,\n",
    "        'validation': new_validation\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../yolov3_data/batch12_yolov3-tf2.json', 'w') as f:\n",
    "    json.dump(new_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../yolov3_data/batch12_yolov3-tf2.json', 'r') as f:\n",
    "    ll = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
